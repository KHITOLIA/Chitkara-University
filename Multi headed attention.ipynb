{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85bef79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66319429",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn((batch_size, sequence_length, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26d98e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd0d728",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3*d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276b7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d57c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0bd11e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 8\n",
    "head_dim = d_model//num_heads\n",
    "qkv = qkv.reshape(batch_size, num_heads, sequence_length , 3*head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5637ea93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd265ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now break this into simple q, k, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02075f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k,v = qkv.chunk(3, dim = -1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d59b1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_k = q.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47140ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = torch.matmul(q,k.transpose(-2, -1))/np.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44c820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "139f74ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.full(scaled.size(), float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "694cc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.triu(mask, diagonal = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c335909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b63d822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e2b9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6306,    -inf,    -inf,    -inf],\n",
       "        [ 0.2766, -0.3240,    -inf,    -inf],\n",
       "        [-0.0979, -0.2961,  0.0378,    -inf],\n",
       "        [ 0.2177, -0.1842, -0.0748,  0.1721]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8d9a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = scaled + mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfc99cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim = -1) # dim = -1 means last dimension mei attention use kiya hai cuz voh row by row context nikalega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcaa4a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6458, 0.3542, 0.0000, 0.0000],\n",
       "          [0.3372, 0.2766, 0.3862, 0.0000],\n",
       "          [0.2967, 0.1985, 0.2214, 0.2834]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6219, 0.3781, 0.0000, 0.0000],\n",
       "          [0.2716, 0.2213, 0.5071, 0.0000],\n",
       "          [0.3096, 0.2237, 0.2087, 0.2581]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.7208, 0.2792, 0.0000, 0.0000],\n",
       "          [0.3975, 0.3232, 0.2793, 0.0000],\n",
       "          [0.3718, 0.1743, 0.1997, 0.2543]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4488, 0.5512, 0.0000, 0.0000],\n",
       "          [0.2671, 0.3425, 0.3904, 0.0000],\n",
       "          [0.2677, 0.2747, 0.2968, 0.1608]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2910, 0.7090, 0.0000, 0.0000],\n",
       "          [0.3545, 0.3726, 0.2729, 0.0000],\n",
       "          [0.3298, 0.1000, 0.1494, 0.4208]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3868, 0.6132, 0.0000, 0.0000],\n",
       "          [0.2661, 0.5161, 0.2179, 0.0000],\n",
       "          [0.2445, 0.0958, 0.2970, 0.3627]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3441, 0.6559, 0.0000, 0.0000],\n",
       "          [0.2565, 0.4881, 0.2554, 0.0000],\n",
       "          [0.1809, 0.2134, 0.2123, 0.3934]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6004, 0.3996, 0.0000, 0.0000],\n",
       "          [0.4084, 0.3643, 0.2273, 0.0000],\n",
       "          [0.2816, 0.2982, 0.2961, 0.1241]]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce7c92cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = torch.matmul(attention, v)\n",
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7024446",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = value.reshape(batch_size, sequence_length, num_heads*head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9959826d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ffbba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4216d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = linear_layer(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4757ea3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d1002c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6098,  0.1974,  0.0480,  ...,  0.0383, -0.0209,  0.2957],\n",
       "         [-0.0973, -0.1122,  0.0256,  ..., -0.1880, -0.0123, -0.4714],\n",
       "         [-0.1467, -0.0171, -0.0209,  ...,  0.1269, -0.1492, -0.1048],\n",
       "         [ 0.0994,  0.3236,  0.1151,  ...,  0.3135,  0.2553,  0.3763]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62a99b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    mask = torch.full(scaled.size(), float('-inf'))\n",
    "    mask = torch.triu(mask, diagonal=1)\n",
    "    scaled = scaled + mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5795bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65050749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 5, 512])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d292ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional encoding\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "204cdcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 10\n",
    "d_model = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a8b56d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_i = torch.arange(0, d_model, 2).float()\n",
    "even_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b05c231",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_denominator = torch.pow(10000, even_i/d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82c11ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45f07653",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_i = torch.arange(1, d_model , 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9b85b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "odd_denominator = torch.pow(10000, (odd_i-1)/d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c1d4b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  1.0000,  21.5443, 464.1590])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73033094",
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = even_denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7870434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(max_len, dtype = torch.float).reshape(max_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44adfc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.],\n",
       "        [5.],\n",
       "        [6.],\n",
       "        [7.],\n",
       "        [8.],\n",
       "        [9.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d727030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_pe = torch.sin(position/denominator)\n",
    "odd_pe = torch.cos(position/denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "26453503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.8415,  0.0464,  0.0022],\n",
       "        [ 0.9093,  0.0927,  0.0043],\n",
       "        [ 0.1411,  0.1388,  0.0065],\n",
       "        [-0.7568,  0.1846,  0.0086],\n",
       "        [-0.9589,  0.2300,  0.0108],\n",
       "        [-0.2794,  0.2749,  0.0129],\n",
       "        [ 0.6570,  0.3192,  0.0151],\n",
       "        [ 0.9894,  0.3629,  0.0172],\n",
       "        [ 0.4121,  0.4057,  0.0194]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90cb90ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000],\n",
       "        [ 0.5403,  0.9989,  1.0000],\n",
       "        [-0.4161,  0.9957,  1.0000],\n",
       "        [-0.9900,  0.9903,  1.0000],\n",
       "        [-0.6536,  0.9828,  1.0000],\n",
       "        [ 0.2837,  0.9732,  0.9999],\n",
       "        [ 0.9602,  0.9615,  0.9999],\n",
       "        [ 0.7539,  0.9477,  0.9999],\n",
       "        [-0.1455,  0.9318,  0.9999],\n",
       "        [-0.9111,  0.9140,  0.9998]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6897f9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack([even_pe, odd_pe], dim = 2)\n",
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b03f9ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.8415,  0.5403],\n",
       "         [ 0.0464,  0.9989],\n",
       "         [ 0.0022,  1.0000]],\n",
       "\n",
       "        [[ 0.9093, -0.4161],\n",
       "         [ 0.0927,  0.9957],\n",
       "         [ 0.0043,  1.0000]],\n",
       "\n",
       "        [[ 0.1411, -0.9900],\n",
       "         [ 0.1388,  0.9903],\n",
       "         [ 0.0065,  1.0000]],\n",
       "\n",
       "        [[-0.7568, -0.6536],\n",
       "         [ 0.1846,  0.9828],\n",
       "         [ 0.0086,  1.0000]],\n",
       "\n",
       "        [[-0.9589,  0.2837],\n",
       "         [ 0.2300,  0.9732],\n",
       "         [ 0.0108,  0.9999]],\n",
       "\n",
       "        [[-0.2794,  0.9602],\n",
       "         [ 0.2749,  0.9615],\n",
       "         [ 0.0129,  0.9999]],\n",
       "\n",
       "        [[ 0.6570,  0.7539],\n",
       "         [ 0.3192,  0.9477],\n",
       "         [ 0.0151,  0.9999]],\n",
       "\n",
       "        [[ 0.9894, -0.1455],\n",
       "         [ 0.3629,  0.9318],\n",
       "         [ 0.0172,  0.9999]],\n",
       "\n",
       "        [[ 0.4121, -0.9111],\n",
       "         [ 0.4057,  0.9140],\n",
       "         [ 0.0194,  0.9998]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a051ade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PE = torch.flatten(stacked, start_dim = 1, end_dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5693d6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 6])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "264f4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self):\n",
    "        even_i = torch.arange(0, self.d_model, 2).float()\n",
    "        denominator = torch.pow(10000, even_i/self.d_model)\n",
    "        position = torch.arange(self.max_sequence_length).reshape(self.max_sequence_length, 1)\n",
    "        even_PE = torch.sin(position / denominator)\n",
    "        odd_PE = torch.cos(position / denominator)\n",
    "        stacked = torch.stack([even_PE, odd_PE], dim=2)\n",
    "        PE = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "        return PE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "000ba39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.5403,  0.0464,  0.9989,  0.0022,  1.0000],\n",
       "        [ 0.9093, -0.4161,  0.0927,  0.9957,  0.0043,  1.0000],\n",
       "        [ 0.1411, -0.9900,  0.1388,  0.9903,  0.0065,  1.0000],\n",
       "        [-0.7568, -0.6536,  0.1846,  0.9828,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.2837,  0.2300,  0.9732,  0.0108,  0.9999],\n",
       "        [-0.2794,  0.9602,  0.2749,  0.9615,  0.0129,  0.9999],\n",
       "        [ 0.6570,  0.7539,  0.3192,  0.9477,  0.0151,  0.9999],\n",
       "        [ 0.9894, -0.1455,  0.3629,  0.9318,  0.0172,  0.9999],\n",
       "        [ 0.4121, -0.9111,  0.4057,  0.9140,  0.0194,  0.9998]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = PositionalEncoding(d_model=6, max_sequence_length=10)\n",
    "pe.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b1ff52",
   "metadata": {},
   "source": [
    "# Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2eb71d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.Tensor([[[0.2, 0.1, 0.3], [0.5, 0.1, 0.1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91cb38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "B, S, E = inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76078953",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.reshape(S, B, E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "595a82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_shape = inputs.size()[-2:]\n",
    "gamma = nn.Parameter(torch.ones(parameter_shape))\n",
    "beta = nn.Parameter(torch.ones(parameter_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bce12b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([1, 3]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta.shape, gamma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "efbb1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dims = [-(i + 1) for i in range(len(parameter_shape))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af420e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [-1, -2]  # for batch dimension and embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f67d0c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -2]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8ea27d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = inputs.mean(dim = dims,  keepdim = True)\n",
    "mean.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f224ae7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0817]],\n",
       "\n",
       "        [[0.1886]]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ((inputs-mean)**2).mean(dim = dims, keepdim = True)\n",
    "epsilon = 1e-5\n",
    "std = (var+epsilon).sqrt()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f1f72fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (inputs-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d0f4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = gamma*y + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7f84bf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000, -0.2238,  2.2238]],\n",
       "\n",
       "        [[ 2.4140,  0.2930,  0.2930]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "042ac9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LayerNormalization():\n",
    "    def __init__(self, parameters_shape, eps=1e-5):\n",
    "        self.parameters_shape=parameters_shape\n",
    "        self.eps=eps\n",
    "        self.gamma = nn.Parameter(torch.ones(parameters_shape))\n",
    "        self.beta =  nn.Parameter(torch.zeros(parameters_shape))\n",
    "\n",
    "    def forward(self, input):\n",
    "        dims = [-(i + 1) for i in range(len(self.parameters_shape))]\n",
    "        mean = inputs.mean(dim=dims, keepdim=True)\n",
    "        print(f\"Mean \\n ({mean.size()}): \\n {mean}\")\n",
    "        var = ((inputs - mean) ** 2).mean(dim=dims, keepdim=True)\n",
    "        std = (var + self.eps).sqrt()\n",
    "        print(f\"Standard Deviation \\n ({std.size()}): \\n {std}\")\n",
    "        y = (inputs - mean) / std\n",
    "        print(f\"y \\n ({y.size()}) = \\n {y}\")\n",
    "        out = self.gamma * y  + self.beta\n",
    "        print(f\"out \\n ({out.size()}) = \\n {out}\")\n",
    "        print('parameter shape ', self.parameters_shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ce12a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input \n",
      " (torch.Size([5, 3, 8])) = \n",
      " tensor([[[-0.7885, -0.4783, -0.5920,  0.2692, -1.0349,  0.2413,  1.2919,\n",
      "           1.7395],\n",
      "         [-1.7447,  0.8992,  0.9784,  0.0715, -0.7955,  1.7451, -1.9119,\n",
      "          -0.6223],\n",
      "         [-0.5215,  1.8098,  0.3279, -1.6558, -1.3841, -0.3033, -1.0581,\n",
      "          -0.5864]],\n",
      "\n",
      "        [[-0.2612,  0.1764,  1.6328,  0.4338,  1.1443, -0.9820, -0.8404,\n",
      "          -0.4170],\n",
      "         [ 0.5260,  0.5908, -0.2610,  0.3541,  1.8695, -0.2470, -0.8677,\n",
      "          -0.0088],\n",
      "         [ 0.8854,  0.1873,  0.8674, -1.2851,  0.4021, -0.4690, -2.0062,\n",
      "          -0.1976]],\n",
      "\n",
      "        [[-2.2157, -0.0656,  0.8522,  1.8787, -1.2984, -0.2642,  0.4032,\n",
      "           1.4360],\n",
      "         [-0.5445, -1.1208,  1.1413, -0.8726,  0.2163,  1.0912,  0.2856,\n",
      "          -0.4894],\n",
      "         [ 1.0202, -0.2206,  1.0396,  0.0276,  1.4310, -0.6794,  1.4389,\n",
      "          -0.1593]],\n",
      "\n",
      "        [[ 0.5882, -0.7973,  0.7749, -1.2714,  0.8682,  0.7185, -0.8039,\n",
      "           1.1034],\n",
      "         [ 1.8745, -0.0967,  2.1536,  0.0386, -0.3955, -0.3806,  0.3332,\n",
      "           0.1351],\n",
      "         [ 0.1139, -0.4882, -0.5087, -0.8374, -0.0132, -0.6291,  0.2793,\n",
      "           1.6969]],\n",
      "\n",
      "        [[-0.3766, -0.1428,  0.2500, -0.5360, -0.5734, -1.1179,  1.3717,\n",
      "          -1.5080],\n",
      "         [ 0.2122,  0.7376, -0.2036, -0.3189,  1.5017,  1.0056,  1.0644,\n",
      "          -0.4842],\n",
      "         [ 1.0855, -0.6418, -1.8565, -0.7462,  0.5934,  1.3854, -1.7873,\n",
      "           1.1603]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "sentence_length = 5\n",
    "embedding_dim = 8 \n",
    "inputs = torch.randn(sentence_length, batch_size, embedding_dim)\n",
    "\n",
    "print(f\"input \\n ({inputs.size()}) = \\n {inputs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "242b063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = LayerNormalization(inputs.size()[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03fde7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean \n",
      " (torch.Size([5, 3, 1])): \n",
      " tensor([[[ 0.0810],\n",
      "         [-0.1725],\n",
      "         [-0.4214]],\n",
      "\n",
      "        [[ 0.1109],\n",
      "         [ 0.2445],\n",
      "         [-0.2020]],\n",
      "\n",
      "        [[ 0.0908],\n",
      "         [-0.0366],\n",
      "         [ 0.4873]],\n",
      "\n",
      "        [[ 0.1476],\n",
      "         [ 0.4578],\n",
      "         [-0.0483]],\n",
      "\n",
      "        [[-0.3291],\n",
      "         [ 0.4393],\n",
      "         [-0.1009]]])\n",
      "Standard Deviation \n",
      " (torch.Size([5, 3, 1])): \n",
      " tensor([[[0.9384],\n",
      "         [1.2398],\n",
      "         [1.0276]],\n",
      "\n",
      "        [[0.8667],\n",
      "         [0.7624],\n",
      "         [0.9580]],\n",
      "\n",
      "        [[1.2789],\n",
      "         [0.8035],\n",
      "         [0.7808]],\n",
      "\n",
      "        [[0.8774],\n",
      "         [0.9298],\n",
      "         [0.7538]],\n",
      "\n",
      "        [[0.8200],\n",
      "         [0.6912],\n",
      "         [1.2412]]])\n",
      "y \n",
      " (torch.Size([5, 3, 8])) = \n",
      " tensor([[[-0.9266, -0.5961, -0.7172,  0.2005, -1.1891,  0.1708,  1.2903,\n",
      "           1.7673],\n",
      "         [-1.2680,  0.8644,  0.9283,  0.1968, -0.5024,  1.5467, -1.4029,\n",
      "          -0.3628],\n",
      "         [-0.0974,  2.1714,  0.7292, -1.2013, -0.9368,  0.1150, -0.6196,\n",
      "          -0.1605]],\n",
      "\n",
      "        [[-0.4293,  0.0756,  1.7561,  0.3726,  1.1924, -1.2609, -1.0975,\n",
      "          -0.6090],\n",
      "         [ 0.3692,  0.4542, -0.6630,  0.1438,  2.1314, -0.6446, -1.4588,\n",
      "          -0.3322],\n",
      "         [ 1.1350,  0.4063,  1.1163, -1.1306,  0.6305, -0.2787, -1.8833,\n",
      "           0.0045]],\n",
      "\n",
      "        [[-1.8035, -0.1223,  0.5954,  1.3981, -1.0862, -0.2775,  0.2443,\n",
      "           1.0519],\n",
      "         [-0.6321, -1.3494,  1.4660, -1.0404,  0.3147,  1.4037,  0.4010,\n",
      "          -0.5635],\n",
      "         [ 0.6826, -0.9066,  0.7074, -0.5887,  1.2087, -1.4943,  1.2189,\n",
      "          -0.8280]],\n",
      "\n",
      "        [[ 0.5022, -1.0769,  0.7150, -1.6173,  0.8214,  0.6507, -1.0845,\n",
      "           1.0894],\n",
      "         [ 1.5236, -0.5963,  1.8238, -0.4508, -0.9176, -0.9016, -0.1340,\n",
      "          -0.3470],\n",
      "         [ 0.2152, -0.5835, -0.6107, -1.0468,  0.0466, -0.7704,  0.4345,\n",
      "           2.3151]],\n",
      "\n",
      "        [[-0.0579,  0.2273,  0.7062, -0.2523, -0.2979, -0.9619,  2.0741,\n",
      "          -1.4376],\n",
      "         [-0.3287,  0.4316, -0.9303, -1.0970,  1.5370,  0.8192,  0.9043,\n",
      "          -1.3362],\n",
      "         [ 0.9558, -0.4358, -1.4144, -0.5199,  0.5594,  1.1975, -1.3587,\n",
      "           1.0161]]])\n",
      "out \n",
      " (torch.Size([5, 3, 8])) = \n",
      " tensor([[[-0.9266, -0.5961, -0.7172,  0.2005, -1.1891,  0.1708,  1.2903,\n",
      "           1.7673],\n",
      "         [-1.2680,  0.8644,  0.9283,  0.1968, -0.5024,  1.5467, -1.4029,\n",
      "          -0.3628],\n",
      "         [-0.0974,  2.1714,  0.7292, -1.2013, -0.9368,  0.1150, -0.6196,\n",
      "          -0.1605]],\n",
      "\n",
      "        [[-0.4293,  0.0756,  1.7561,  0.3726,  1.1924, -1.2609, -1.0975,\n",
      "          -0.6090],\n",
      "         [ 0.3692,  0.4542, -0.6630,  0.1438,  2.1314, -0.6446, -1.4588,\n",
      "          -0.3322],\n",
      "         [ 1.1350,  0.4063,  1.1163, -1.1306,  0.6305, -0.2787, -1.8833,\n",
      "           0.0045]],\n",
      "\n",
      "        [[-1.8035, -0.1223,  0.5954,  1.3981, -1.0862, -0.2775,  0.2443,\n",
      "           1.0519],\n",
      "         [-0.6321, -1.3494,  1.4660, -1.0404,  0.3147,  1.4037,  0.4010,\n",
      "          -0.5635],\n",
      "         [ 0.6826, -0.9066,  0.7074, -0.5887,  1.2087, -1.4943,  1.2189,\n",
      "          -0.8280]],\n",
      "\n",
      "        [[ 0.5022, -1.0769,  0.7150, -1.6173,  0.8214,  0.6507, -1.0845,\n",
      "           1.0894],\n",
      "         [ 1.5236, -0.5963,  1.8238, -0.4508, -0.9176, -0.9016, -0.1340,\n",
      "          -0.3470],\n",
      "         [ 0.2152, -0.5835, -0.6107, -1.0468,  0.0466, -0.7704,  0.4345,\n",
      "           2.3151]],\n",
      "\n",
      "        [[-0.0579,  0.2273,  0.7062, -0.2523, -0.2979, -0.9619,  2.0741,\n",
      "          -1.4376],\n",
      "         [-0.3287,  0.4316, -0.9303, -1.0970,  1.5370,  0.8192,  0.9043,\n",
      "          -1.3362],\n",
      "         [ 0.9558, -0.4358, -1.4144, -0.5199,  0.5594,  1.1975, -1.3587,\n",
      "           1.0161]]], grad_fn=<AddBackward0>)\n",
      "parameter shape  torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "out = layer_norm.forward(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351dbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae755a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
