{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb88b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c89e80f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l,d_k,d_v = 4, 8, 8\n",
    "q = np.random.randn(l, d_k)  # l is number of words in a input my name is ajay 4\n",
    "k = np.random.randn(l, d_k)  # size of each vectors is 8\n",
    "v = np.random.randn(l, d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "067686b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.31340509  0.55679969  0.03193698  0.5822728   0.45087687 -1.0763082\n",
      "  -0.79020352 -0.43132768]\n",
      " [ 0.74774782  1.19683398  0.74409719 -1.5994998  -0.09815244 -1.01712905\n",
      "   0.60803932 -0.0090187 ]\n",
      " [ 0.81938897  0.04747731  0.04071351  0.11471136  1.48537342 -0.30578805\n",
      "  -0.29083539 -0.05305894]\n",
      " [ 0.82826612 -1.06810048  0.52408215  1.87113025 -0.71062143 -1.33563895\n",
      "  -0.8284647  -1.16136434]]\n",
      "K\n",
      " [[-1.25788425  0.25182244  0.97716912 -2.07695523 -0.34085481 -1.39546788\n",
      "   0.93037477  0.69155303]\n",
      " [-0.62404629 -0.53228218  1.0345739   1.64439884  1.52175721  0.23191807\n",
      "   0.11660546 -1.99797336]\n",
      " [-1.40787588  1.00486721  0.43193026  2.5152917  -0.19986458  0.48731247\n",
      "  -0.50466816  1.30512379]\n",
      " [ 1.0799233   0.43490982  0.37766703 -1.43097862 -1.34308552 -1.04603835\n",
      "  -2.4470978  -0.62708596]]\n",
      "V\n",
      " [[-0.77629822  0.14781796  1.47112785  1.16439496 -0.645503   -1.38168076\n",
      "   1.4121527   0.43674903]\n",
      " [-0.66935406 -0.61675843  1.61672049 -0.00638761  0.06507838  0.65538523\n",
      "  -1.92948627  0.59015314]\n",
      " [ 1.70377469  0.78931591  0.20977516  0.60866978  0.21495862 -1.67282148\n",
      "  -0.47970878 -1.31721971]\n",
      " [ 0.35872263  0.81561014  0.35306294 -2.18587685 -1.4404991  -1.21933652\n",
      "   0.36464831 -0.40059006]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643e9d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31340509,  0.55679969,  0.03193698,  0.5822728 ,  0.45087687,\n",
       "       -1.0763082 , -0.79020352, -0.43132768])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3a21e6",
   "metadata": {},
   "source": [
    "# Self Attention  \n",
    "self attention = softmax(Q.K.T/sqrt(d_k) + M)V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab0f81cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.11736077,  1.70472502,  0.81789657,  2.48393102],\n",
       "       [ 5.42230189, -3.26040971, -4.34655847,  3.61140306],\n",
       "       [-1.60406525,  1.95570169, -1.16813264, -0.17339011],\n",
       "       [-4.15283911,  4.50335999,  1.08694034,  3.05748197]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e62552",
   "metadata": {},
   "source": [
    "# so here it's first row is corresponds to my vector and this my has some relation with other words in it's corresponding columns\n",
    "1. so here my is more focused on name here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e8809",
   "metadata": {},
   "source": [
    "Why we need sqrt of D_K : need to minimize the variance and stablize this matmul of Q, K.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "776532ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7012312571928682, 1.423723752396705, 8.371570150689042)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a0cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = np.matmul(q, k.T)/np.sqrt(d_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3423f114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.04644626883613"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7e467d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39504669,  0.60271131,  0.28917011,  0.87820223],\n",
       "       [ 1.91707322, -1.15272891, -1.53674048,  1.2768238 ],\n",
       "       [-0.56712271,  0.69144496, -0.41299726, -0.06130266],\n",
       "       [-1.46825035,  1.59217819,  0.38429144,  1.08098312]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c9a377",
   "metadata": {},
   "source": [
    "# Masking : so that we can ensure the words don't get the context from words generated in future \n",
    "1. not required in decorder but in encoder cuz input is going simulatenously not in encoder one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f38bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.tril(np.ones((l,l) )) # traingular matrix with one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "414fd852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482938e",
   "metadata": {},
   "source": [
    "1. here first row represents my \n",
    "2. now second focus on my name \n",
    "3. my name is and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18f4c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.tril(np.ones((l,l) )) # traingular matrix with one \n",
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1702029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89820d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39504669,        -inf,        -inf,        -inf],\n",
       "       [ 1.91707322, -1.15272891,        -inf,        -inf],\n",
       "       [-0.56712271,  0.69144496, -0.41299726,        -inf],\n",
       "       [-1.46825035,  1.59217819,  0.38429144,  1.08098312]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e45acc0",
   "metadata": {},
   "source": [
    "# Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eadf025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T/ np.sum(np.exp(x), axis = 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ee8ba75",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = softmax(scaled + mask) #that's why mask is need we didn't need te context of generated words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ee2d3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.95562978, 0.04437022, 0.        , 0.        ],\n",
       "       [0.17583924, 0.61902016, 0.2051406 , 0.        ],\n",
       "       [0.02409058, 0.51401353, 0.15360169, 0.3082942 ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70c9763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_v = np.matmul(attention,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fe520f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.77629822,  0.14781796,  1.47112785,  1.16439496, -0.645503  ,\n",
       "        -1.38168076,  1.4121527 ,  0.43674903],\n",
       "       [-0.77155308,  0.11389354,  1.47758783,  1.11244708, -0.61397435,\n",
       "        -1.2912957 ,  1.26388346,  0.4435556 ],\n",
       "       [-0.20133397, -0.19387296,  1.30249797,  0.32565515, -0.02912318,\n",
       "        -0.18042063, -1.04448679,  0.17189906],\n",
       "       [ 0.00953626,  0.05922697,  1.0075256 , -0.5556328 , -0.39317888,\n",
       "        -0.32927121, -0.91902759, -0.01195853]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7763c7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.77629822,  0.14781796,  1.47112785,  1.16439496, -0.645503  ,\n",
       "        -1.38168076,  1.4121527 ,  0.43674903],\n",
       "       [-0.66935406, -0.61675843,  1.61672049, -0.00638761,  0.06507838,\n",
       "         0.65538523, -1.92948627,  0.59015314],\n",
       "       [ 1.70377469,  0.78931591,  0.20977516,  0.60866978,  0.21495862,\n",
       "        -1.67282148, -0.47970878, -1.31721971],\n",
       "       [ 0.35872263,  0.81561014,  0.35306294, -2.18587685, -1.4404991 ,\n",
       "        -1.21933652,  0.36464831, -0.40059006]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b7b7990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after using attention we can see my having context and next word getting so much of context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78012bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return (np.exp(x).T/ np.sum(np.exp(x), axis = 1)).T\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask):\n",
    "    d_k = q.shape[-1]\n",
    "\n",
    "    scaled = np.matmul(q, k.T)/ np.sqrt(d_k)\n",
    "    attention = softmax(scaled + mask)\n",
    "    \n",
    "    output_v = np.matmul(attention, v)\n",
    "    \n",
    "    return output_v, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbeabf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[-2.82239293 -0.47236277 -0.04448361  1.06968885 -0.35909733 -0.63237679\n",
      "  -0.96846493 -0.92082198]\n",
      " [ 0.7993451  -0.05727779 -0.77572556  0.67483218 -1.19270505  1.49999854\n",
      "   0.20769235  1.19580674]\n",
      " [-0.73461647  0.79470803  0.90457411 -0.13794276  0.2626833  -0.4164732\n",
      "  -0.80817525  1.73471066]\n",
      " [ 1.01259856 -0.64249233  0.19130425  0.8676278   1.26207273  0.0970803\n",
      "  -0.59029314 -0.11829099]]\n",
      "K\n",
      " [[ 0.73585521 -0.53771955  0.08794401  1.01987147  0.22819695  0.88969509\n",
      "   0.24045278  0.16817388]\n",
      " [-0.53384289 -1.05438514  0.49406938 -0.79753462 -0.66319722  0.74923826\n",
      "  -0.33447856  0.4277864 ]\n",
      " [ 2.49487759  1.23208374 -1.25320365  0.86076107  0.24320857 -0.04221494\n",
      "  -1.45408512 -0.07658606]\n",
      " [-0.38344551  0.1520428   1.35336729 -0.07491407  2.08894245 -1.97275519\n",
      "   0.73294222 -0.27002603]]\n",
      "V\n",
      " [[ 0.10950061 -0.02226883  1.84966235  0.11710753  1.31396154  1.43469362\n",
      "   1.03162257 -0.22330707]\n",
      " [ 0.40759364  1.68468131 -0.89672188 -0.1986948  -2.03949484  0.45643565\n",
      "   0.17906457  0.38041381]\n",
      " [ 1.25241979 -0.42042291 -0.31069738 -0.10735067  1.5838297   1.1812526\n",
      "  -0.39946162  0.99079045]\n",
      " [-0.73987409 -0.29538044 -0.78992723  0.08198352 -0.19348379 -1.31658206\n",
      "  -0.51798681 -0.46301098]]\n"
     ]
    }
   ],
   "source": [
    "q = np.random.randn(l, d_k)  # l is number of words in a input my name is ajay 4\n",
    "k = np.random.randn(l, d_k)  # size of each vectors is 8\n",
    "v = np.random.randn(l, d_k)\n",
    "mask = np.tril(np.ones((q.shape[0], q.shape[0]) )) # traingular matrix with one \n",
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0\n",
    "vector , attention = scaled_dot_product(q, k, v, mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "305cfd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.09500611e-01, -2.22688285e-02,  1.84966235e+00,\n",
       "          1.17107535e-01,  1.31396154e+00,  1.43469362e+00,\n",
       "          1.03162257e+00, -2.23307071e-01],\n",
       "        [ 2.20337026e-01,  6.12406322e-01,  8.28506677e-01,\n",
       "         -3.13525757e-04,  6.70853863e-02,  1.07095949e+00,\n",
       "          7.14625975e-01,  1.16734615e-03],\n",
       "        [ 5.63063973e-01,  6.90895200e-01, -5.78694496e-02,\n",
       "         -9.57350436e-02, -2.26145922e-01,  8.95279997e-01,\n",
       "          2.33108550e-01,  3.96608731e-01],\n",
       "        [ 4.12659503e-01, -1.05584423e-01,  1.13462016e-01,\n",
       "         -1.07582381e-02,  7.94313960e-01,  6.12791726e-01,\n",
       "          9.25749082e-03,  2.75732361e-01]]),\n",
       " array([[1.        , 0.        , 0.        , 0.        ],\n",
       "        [0.62818179, 0.37181821, 0.        , 0.        ],\n",
       "        [0.24753429, 0.48109795, 0.27136776, 0.        ],\n",
       "        [0.27043676, 0.08472199, 0.41440458, 0.23043667]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3a3b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f4619a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fce2b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8291d6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
